{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问答系统(Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载SubjQA数据集\n",
    "\n",
    "from datasets import get_dataset_config_names\n",
    "\n",
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 可以看到：SubjQA数据集共有6大领域，分别为：\n",
    "> - 图书\n",
    "> - 电子产品\n",
    "> - 零货\n",
    "> - 电影\n",
    "> - 餐饮\n",
    "> - 旅游建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在本次案例中使用电子这个领域\n",
    "from datasets import load_dataset\n",
    "\n",
    "subjqa = load_dataset(\"subjqa\",name=\"electronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : Is this music song have a goo bass?\n",
      "True Answer : {'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n"
     ]
    }
   ],
   "source": [
    "# question和answer键来取出分别的字符串集合\n",
    "print(f\"Question : {subjqa['train']['question'][1]}\")\n",
    "print(f\"True Answer : {subjqa['train']['answers'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in train : 1295\n",
      "Number of questions in test : 358\n",
      "Number of questions in validation : 255\n"
     ]
    }
   ],
   "source": [
    "# 使用flatten()展开并详细的看看数据集\n",
    "import pandas as pd\n",
    "\n",
    "dfs = {split:dest.to_pandas() for split,dest in subjqa.flatten().items()}\n",
    "\n",
    "for split,df in dfs.items():\n",
    "    print(f\"Number of questions in {split} : {df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SubjQA数据集中的常用列名：\n",
    "> - title：亚马逊商品标准认证码\n",
    "> - question：问题\n",
    "> - answer.answer_text：注释者标记的评论中的文本跨度\n",
    "> - answer.answer_start：回答的开始字符索引\n",
    "> - context：上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers.text</th>\n",
       "      <th>answers.answer_start</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>B005DKZTMG</td>\n",
       "      <td>Does the keyboard lightweight?</td>\n",
       "      <td>[this keyboard is compact]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>B00AAIPT76</td>\n",
       "      <td>How is the battery?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I bought this after the first spare gopro batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                        question                answers.text  \\\n",
       "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
       "1159  B00AAIPT76             How is the battery?                          []   \n",
       "\n",
       "     answers.answer_start                                            context  \n",
       "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
       "1159                   []  I bought this after the first spare gopro batt...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 简单采样一些数据\n",
    "qa_cols = ['title','question','answers.text','answers.answer_start','context']\n",
    "\n",
    "sample_df = dfs['train'][qa_cols].sample(2,random_state=7)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，数据集中存在了以下几个情况：\n",
    "- 蹩脚的语法\n",
    "- 空的`answers.text`或者`answers.answer_start`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this keyboard is compact'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用开始索引和结束索引推断回答\n",
    "start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\n",
    "end_idx = start_idx + len(sample_df['answers.text'].iloc[0][0])\n",
    "\n",
    "sample_df['context'].iloc[0][start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 接下来，我们看看消费者更喜欢使用什么口吻来问问题\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = {}\n",
    "question_types = [\"What\",\"How\",\"Is\",\"Does\",\"Do\",\"Was\",\"Where\",\"Why\"]\n",
    "\n",
    "for qt in question_types:\n",
    "    counts[qt] = dfs['train']['question'].str.startswith(qt).value_counts()[True]\n",
    "\n",
    "pd.Series(counts).sort_values().plot.barh()\n",
    "plt.title(\"Frequency of Question Types\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从文本中提取答案\n",
    "在本节中，我们需要理解如何：\n",
    "- 表达进度学习问题\n",
    "- 词元话并编码QA任务的文本\n",
    "- 解决超出模型最大上下文大小的超长篇幅文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 范围识别(Span Classification)\n",
    "最常见的从文本中提取答案的方法是将问题是范围识别任务，其中开始和结束次元中词元将作为一个标签需要模型进行预测。\n",
    "![SpanClassification](SpanClassification.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# 由于我们的数据集实在是太小了，拢共才1908条，因此我们需要一个已经通过超大语料训练好的QA模型\n",
    "# 这里我们将使用deepset的minilm-uncased-squad2模型\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行简单的尝试\n",
    "question = \"How much music can this hold?\"\n",
    "context = \"An MP3 is about 1MB/minute,so about 6000 hours depending on file size.\"\n",
    "\n",
    "inputs = tokenizer(question,context,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_ids</th>\n",
       "      <td>101</td>\n",
       "      <td>2129</td>\n",
       "      <td>2172</td>\n",
       "      <td>2189</td>\n",
       "      <td>2064</td>\n",
       "      <td>2023</td>\n",
       "      <td>2907</td>\n",
       "      <td>1029</td>\n",
       "      <td>102</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>2061</td>\n",
       "      <td>2055</td>\n",
       "      <td>25961</td>\n",
       "      <td>2847</td>\n",
       "      <td>5834</td>\n",
       "      <td>2006</td>\n",
       "      <td>5371</td>\n",
       "      <td>2946</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_type_ids</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attention_mask</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0     1     2     3     4     5     6     7    8     9   ...  \\\n",
       "input_ids       101  2129  2172  2189  2064  2023  2907  1029  102  2019  ...   \n",
       "token_type_ids    0     0     0     0     0     0     0     0    0     1  ...   \n",
       "attention_mask    1     1     1     1     1     1     1     1    1     1  ...   \n",
       "\n",
       "                  18    19     20    21    22    23    24    25    26   27  \n",
       "input_ids       2061  2055  25961  2847  5834  2006  5371  2946  1012  102  \n",
       "token_type_ids     1     1      1     1     1     1     1     1     1    1  \n",
       "attention_mask     1     1      1     1     1     1     1     1     1    1  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {}\n",
    "for k in inputs.keys():\n",
    "    data[k] = inputs[k].numpy()[0]\n",
    "pd.DataFrame(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] how much music can this hold? [SEP] an mp3 is about 1mb / minute, so about 6000 hours depending on file size. [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用解码函数来查看tokenizer是如何编码QA任务的输入的\n",
    "\n",
    "tokenizer.decode(inputs['input_ids'][0])# 编码的格式为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-1.1224, -4.7834, -5.3935, -5.2447, -5.2899, -5.4980, -4.9885, -6.1783,\n",
       "         -1.1224,  0.3651, -0.0807, -1.5551,  3.9556,  4.9206, -2.7833, -3.7461,\n",
       "         -1.7211, -4.6096, -1.3769,  4.0256,  4.9715, -0.2477, -3.0354, -4.8180,\n",
       "         -2.2386, -3.4867, -3.5462, -1.1224]]), end_logits=tensor([[-1.0707, -5.4841, -5.0303, -5.1770, -5.4496, -5.5120, -5.2013, -4.6178,\n",
       "         -1.0707, -3.7223, -0.7583, -3.6969, -2.9205, -1.7346,  0.3122, -2.8688,\n",
       "          4.8807,  0.2692, -3.1317, -3.2404,  0.8239,  5.6645, -0.2568, -4.8910,\n",
       "         -3.1677, -0.0130,  1.6739, -1.0707]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 让模型处理编码后的输入\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于QA模型的目的是“去头去尾留中间”，所以我们需要先获取输出的开始和结束张量\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape : torch.Size([1, 28])\n",
      "Start logits shape : torch.Size([1, 28])\n",
      "End logits shape : torch.Size([1, 28])\n"
     ]
    }
   ],
   "source": [
    "# 输入、开始、结束张量应与编码的输入同长\n",
    "\n",
    "print(f\"Input IDs shape : {inputs.input_ids.size()}\")\n",
    "print(f\"Start logits shape : {start_logits.size()}\")\n",
    "print(f\"End logits shape : {end_logits.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much music can this hold?\n",
      "Answer: 6000 hours\n"
     ]
    }
   ],
   "source": [
    "# 使用argmax并截取出最终的结果\n",
    "import torch\n",
    "\n",
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "\n",
    "answer = tokenizer.decode(answer_span)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:326: UserWarning: topk parameter is deprecated, use top_k instead\n",
      "  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2436027079820633, 'start': 36, 'end': 46, 'answer': '6000 hours'},\n",
       " {'score': 0.23150865733623505,\n",
       "  'start': 16,\n",
       "  'end': 46,\n",
       "  'answer': '1MB/minute,so about 6000 hours'},\n",
       " {'score': 0.10571719706058502,\n",
       "  'start': 16,\n",
       "  'end': 26,\n",
       "  'answer': '1MB/minute'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用pipeline流水线化QA过程\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\",model=model,tokenizer=tokenizer)\n",
    "pipe(question=question,context=context,topk=3) # 考虑到pipe默认会对分数进行排序，因此直接掏第一个就成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 长篇幅处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 像其他的文本分类任务，例如情感判断(Sentiment)，你可以使用缩减长文本的办法来实现相同的模型训练效果，毕竟你的核心任务是将整个sequence进行编码后再交给模型，再使用softmax得到一个[1,num_classes]张量。但是这招在QA系统上是完全行不通的，这会产生欺骗行为在上下文的结尾，因此我们需要一个更合理的，不缩水的处理方法，即滑动窗口(*Sliding Window*)。  \n",
    "通过不断将文本进行缩小，并添加空挡的方式，实现问题和捕获上下文的分离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# 使用return_overflowing_tokens=True来使得模型能够使用动态滑窗\n",
    "# 并且使用doc_stride_max_length来控制滑窗空挡的大小\n",
    "\n",
    "example = dfs['train'].iloc[0][['question','context']]\n",
    "tokenized_example = tokenizer(example['question'],example['context'],return_overflowing_tokens=True,max_length=100,stride=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window #0 has 100 tokens.\n",
      "Window #1 has 88 tokens.\n"
     ]
    }
   ],
   "source": [
    "# 检查分窗的容量\n",
    "for idx,window in enumerate(tokenized_example['input_ids']):\n",
    "    print(f\"Window #{idx} has {len(window)} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window #0 :\n",
      " [CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP]\n",
      "Window #1 :\n",
      " [CLS] how is the bass? [SEP] and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# 最终来看看每个窗内的文本是什么样子的\n",
    "for idx,window in enumerate(tokenized_example['input_ids']):\n",
    "    print(f\"Window #{idx} :\\n {tokenizer.decode(window)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Haystack来构建QA管道\n",
    "\n",
    "> 在我们前面的系统中，我们是将回答上下文和问题是作为一个整体输入到模型当中来，可现实是我们的QA系统应仅仅接受一个问题，而答案是需要模型自己来进行推断的。  \n",
    "> 一种简单粗暴地方法就是直接把`一坨`回答杂糅到一起喂给模型，这么看似乎确实合理，但这会导致模型无法处理这样的超长文本，因此我们需要一个更好的方法来处理这个问题。  \n",
    "> 为了解决这个问题，现代QA系统基本上基于`检索器-阅读器`的架构来实现，其中的几个重要组件如下：  \n",
    "> - 检索器：检索的质量和反馈很大程度上取决于输入问题的质量。检索器通常分为两种：`稀疏`和`密集`。稀疏检索通常将词频作为一个稀疏矩阵来表述文档和问题。通过内积计算来得到问题和文档的相似度向量。另一方面，密集检索器通常使用像Transformer家族的编码器来生成一个上下文嵌入来表示问题和文档。这些嵌入编码了语义，以使得检索器可以通过理解搜索内容的方式来提升搜索精确度。  \n",
    "> - 阅读器：阅读器的主要作用是提取从检索器提供的文档中获得目标答案，通常这类模型是一种阅读理解模型。\n",
    "![QAPipeLine](NormallyQAPipeLine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Haystack是一个基于检索器-阅读器架构的QA系统，深度绑定HuggingFace Transformer库实现。  \n",
    "> Haystack有两个重要的组成部件，分别为：\n",
    "> - DocumentStore：面向文档数据库，用于存储文档和元数据以提供给检索器\n",
    "> - PipeLine：将QA系统内组件进行整合，并允许自定义键值，从多个检索器实例中提取并聚合文档，等等...  \n",
    "> 在开始之前，我们需要安装[ElasticSearch和HayStack](https://haystack.deepset.ai/tutorials/03_scalable_qa_system)  \n",
    "  \n",
    "> ※请务必安装zlib和libjpg※  \n",
    "```bash\n",
    "sudo apt-get install libjpeg-dev zlib1g-dev\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动ElasticSearch\n",
    "import os\n",
    "from subprocess import Popen,PIPE,STDOUT\n",
    "\n",
    "es_server = Popen(args=[\"/root/elasticsearch-7.9.2/bin/elasticsearch\"],stdout=PIPE,stderr=STDOUT,preexec_fn=lambda:os.setuid(1))\n",
    "\n",
    "# 等待ElasticSearch启动\n",
    "!sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "import os\n",
    "\n",
    "# Get the host where Elasticsearch is running, default to localhost\n",
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "# 创建一个ElasticSearch的文档存储\n",
    "document_store = ElasticsearchDocumentStore(host=host, username=\"\", password=\"\",return_embedding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 默认情况下，`ElasticsearchDocumentStore`会生成两个指针，其中一个称之为`document`用于存储文档，而另一个称之为`label`用于存储已标记的回答空挡。  \n",
    "> 现在我们只需要将SubjQA数据集填充给`ElasticsearchDocumentStore`即可。改类接受的元数据类型为`list[dictionary]`，且必须含有`text`和`meta`标签\n",
    "```json\n",
    "{\n",
    "    \"text\":\"<the-context>\",\n",
    "    \"meta\":{\n",
    "        \"filed_01\":\"<additional-metadata>\",\n",
    "        \"filed_02\":\"<additional-metadata>\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1615 documents.\n"
     ]
    }
   ],
   "source": [
    "# 为document_store写入数据\n",
    "for split,df in dfs.items():\n",
    "    # 去除重复项目\n",
    "    docs = [\n",
    "        {\n",
    "            \"text\":row['context'], # 在新版Haystack中，content字段是必须的，旧版的text字段已经被废弃\n",
    "            \"meta\":{\n",
    "                \"item_id\":row['title'],\n",
    "                \"question_id\":row['id'],\n",
    "                \"split\":split\n",
    "            }\n",
    "        }\n",
    "        for _,row in df.drop_duplicates(subset=['context']).iterrows()\n",
    "    ]\n",
    "    document_store.write_documents(docs,index=\"document\")\n",
    "\n",
    "print(f\"Loaded {document_store.get_document_count()} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化检索器\n",
    "在本实验中，我们将使用一个基于稀疏矩阵和TF-IDF(余弦相似度)算法的检索器：`BM25Retriever`。  \n",
    "BM25分数衡量搜索查询中有多少匹配文本，并通过快速饱和TF值和规范文档长度来改进TF-IDF，从而使短文档比长文档更受青睐。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BM25Retriever\n",
    "from haystack.retriever import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple query test\n",
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\"\n",
    "\n",
    "retrieved_docs = retriever.retrieve(query=query,top_k=3,filters={\"item_id\":[item_id],\"split\":[\"train\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic.  I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle.  So the Fire combines for me what I needed all three to do. So far so good.', 'content_type': 'text', 'score': 0.6857824513476455, 'meta': {'item_id': 'B0074BW614', 'question_id': '868e311275e26dbafe5af70774a300f3', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '252e83e25d52df7311d597dc89eef9f6'}\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化阅读器\n",
    "在HayStack中，有两种常用的阅读器：\n",
    "- FARMReader：基于deepset的FARM架构用于微调和部署transformer模型。与使用Hugging Face API训练的模型相兼容，可以直接加载或者从远程Hugging Face GIT存储库进行加载。\n",
    "- TransformerReader：基于Hugging Face的transformer QA管道。仅适用于推理工作流。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管阅读器都以相同的方式来处理模型权重，但仍然有不同区别之处：\n",
    "- 在HuggingFace Transformers中，QA管道将在每篇文章中使用`softmax`来标准化开始和结束预测值。这意味着只有在同一篇文章中提取的答案之间比较答案得分才有意义，其中置信度的总值为1。  \n",
    "- 在`TransformerReader`类中有时会出现相同的预测，但是分数不同。这尤其会在长文本中发生如果答案需要依赖两个重叠窗口(*Overlapping Windows*)。好消息是：在FARM中这些重复结果将默认被移除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 加载MiniLM模型\n",
    "from haystack.reader.farm import FARMReader # 在旧版API中使用from haystack.reader.farm import FARMReader\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "max_seq_length,doc_stride = 384,128\n",
    "reader = FARMReader(model_name_or_path=model_ckpt,progress_bar=False,max_seq_len=max_seq_length,doc_stride=doc_stride,return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'How much music can this hold?', 'no_ans_gap': 12.829151630401611, 'answers': [<Answer {'answer': '6000 hours', 'type': 'extractive', 'score': 0.5138806104660034, 'context': 'An MP3 is about 1MB/minute,so about 6000 hours depending on file size.', 'offsets_in_document': [{'start': 36, 'end': 46}], 'offsets_in_context': [{'start': 36, 'end': 46}], 'document_ids': ['bef233935fb49897d219b15700915833'], 'meta': {}}>]}\n"
     ]
    }
   ],
   "source": [
    "# 简单使用reader进行测试\n",
    "print(reader.predict_on_texts(\n",
    "    question=question,\n",
    "    texts=[context],\n",
    "    top_k=1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将两个组件合并为QA管道\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "# 定义一个QA管道\n",
    "pipe = ExtractiveQAPipeline(reader=reader,retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让模型生成多个答案\n",
    "n_answer = 3\n",
    "preds = pipe.run(\n",
    "    query=query,\n",
    "    params={\"Retriever\":{\"top_k\":3},\"Reader\":{\"top_k\":n_answer},\"filters\":{\"item_id\":[item_id],\"split\":[\"train\"]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is it good for reading? \n",
      "\n",
      "Answer 1: it is great for reading books when no light is available\n",
      "Review snippet: ...ecoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest good headphones t...\n",
      "\n",
      "\n",
      "\n",
      "Answer 2: I mainly use it for book reading\n",
      "Review snippet: ... is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my la...\n",
      "\n",
      "\n",
      "\n",
      "Answer 3: \n",
      "Review snippet: ...None...\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {preds['query']} \\n\")\n",
    "for idx in range(n_answer):\n",
    "    print(f\"Answer {idx+1}: {preds['answers'][idx].to_dict()['answer']}\")\n",
    "    print(f\"Review snippet: ...{preds['answers'][idx].to_dict()['context']}...\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 提升QA系统性能的关键并不是提升你阅读器的性能，因为就算我们不断的调优阅读器的性能吗，但是一旦它第一时间无法找到相关联的文档，一切都是白扯。  \n",
    "> 实际上，在QA管线中，真正会影响QA性能的上限的是：检索器的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证检索器的性能\n",
    "一种常见的验证和评估检索器的方法称之为`回召(Recall)`，用于评估所有检索的关联文档的百分比。在本文中，“相关”仅简单的表述答案是否出现在文档中，所以给到一个问题集，我们可以通过统计一个答案出现在top_k文档中的次数进而计算其召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在HayStack中又两种普遍的方式来评估检索器的性能：\n",
    "- 使用检索器内置的`eval()`函数。这样既可以用于开放和闭合域的QA系统，但不是所有的数据集都像SubjQA一样每个文档都一个与之配对简单的产品，并且我们需要使用产品ID来过滤每个`query`。\n",
    "- 构建一个简单的管道来讲一个检索器和`EvalRetriever`类进行绑定。这允许自定义评分和query过滤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 密集文章检索(Dense Passage Retrieval)\n",
    "如何在更小的*top_k*值下实现更高的召回率呢？类BM25检索器存在一种普遍的限制是：它不会捕捉到相关联的文档，这种情况会发生在当用户输入的问题存在包含了不匹配这些评论中存在的术语。  \n",
    "一种可行的替换方式是使用密度嵌入(*Dense Embeddings*)来表示问题和文档，并且当前最流行的方法是使用`Dense Passage Retrieval(DPR)`，其核心思想是使用两个BERT模型作为问题和文章的编码器。  \n",
    "具体工作流程如下图，编码器匹配输入文本并将其转换为一个*n维*的向量作为`[CLS]`词元。  \n",
    "<img src=\"DPRWorkflow.png\" width=\"500\" height=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
